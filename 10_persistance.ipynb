{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef408bc",
   "metadata": {},
   "source": [
    "## Memory Implementation \n",
    "We can user it as Resume conversation or new conversation page by assisgning different thread id's\n",
    "-> Short term memory\n",
    "-> Fault tolerance\n",
    "-> Human in the loop\n",
    "-> Time travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f06ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the module\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver #Saves in RAM\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef4cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59bc0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a state\n",
    "class JokeState(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    explanation : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7156eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of joke\n",
    "def gen_joke(state: JokeState):\n",
    "    prompt = f\" Generate a funny joke from the topic {state[\"topic\"]}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"joke\": response}\n",
    "\n",
    "def gen_explanation(state: JokeState):\n",
    "    prompt = f\"{state[\"joke\"]} This is a joke, I want you to explain it.\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"explanation\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f0efd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000002826C3254C0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a graph\n",
    "graph = StateGraph(JokeState)\n",
    "\n",
    "# Creating nodes\n",
    "graph.add_node('gen_joke', gen_joke)\n",
    "graph.add_node('gen_explanation', gen_explanation)\n",
    "\n",
    "# creating edges\n",
    "graph.add_edge(START, 'gen_joke')\n",
    "graph.add_edge('gen_joke', 'gen_explanation')\n",
    "graph.add_edge('gen_explanation', END)\n",
    "\n",
    "# Creating thing for memory\n",
    "checkpointer = InMemorySaver()\n",
    "# Compiling with memory\n",
    "workflow = graph.compile(checkpointer)\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a88b641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why did the pizza go to therapy? \\n\\nBecause it was feeling crusty and had a lot of topping issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 43, 'total_tokens': 67, 'completion_time': 0.026194333, 'prompt_time': 0.084625438, 'queue_time': 0.061955262, 'total_time': 0.110819771}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8b8323f-712c-4afb-a662-fec948fb6e40-0', usage_metadata={'input_tokens': 43, 'output_tokens': 24, 'total_tokens': 67}),\n",
       " 'explanation': AIMessage(content='This is a joke about a pizza going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the pizza go to therapy?\" This is a common joke format where the punchline is a play on words or a unexpected twist.\\n- The punchline is \"Because it was feeling crusty and had a lot of topping issues.\" This is where the joke is. The word \"crusty\" has a double meaning here:\\n  - A pizza crust is the outer layer of a pizza, which is often crispy or crunchy.\\n  - The phrase \"feeling crusty\" is also an idiom that means feeling grumpy or irritable.\\n- The phrase \"had a lot of topping issues\" is also a play on words:\\n  - A pizza topping is a ingredient added on top of the pizza, such as cheese, pepperoni, or vegetables.\\n  - The phrase \"topping issues\" sounds like \"tough issues\" or \"problems\", implying that the pizza has emotional or psychological issues that it needs to work through in therapy.\\n\\nOverall, the joke is a play on words and uses the common format of a joke to create a humorous connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 253, 'total_tokens': 500, 'completion_time': 0.367460049, 'prompt_time': 0.065347236, 'queue_time': 0.045347873, 'total_time': 0.432807285}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e272e9b9-cf4a-4865-bcf6-331b93463de1-0', usage_metadata={'input_tokens': 253, 'output_tokens': 247, 'total_tokens': 500})}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executing workflow\n",
    "thread_id = '1'\n",
    "config = {'configurable': {'thread_id': thread_id}}\n",
    "workflow.invoke({\"topic\":\"pizza\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b34c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why did the pizza go to therapy? \\n\\nBecause it was feeling crusty and had a lot of topping issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 43, 'total_tokens': 67, 'completion_time': 0.026194333, 'prompt_time': 0.084625438, 'queue_time': 0.061955262, 'total_time': 0.110819771}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8b8323f-712c-4afb-a662-fec948fb6e40-0', usage_metadata={'input_tokens': 43, 'output_tokens': 24, 'total_tokens': 67}), 'explanation': AIMessage(content='This is a joke about a pizza going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the pizza go to therapy?\" This is a common joke format where the punchline is a play on words or a unexpected twist.\\n- The punchline is \"Because it was feeling crusty and had a lot of topping issues.\" This is where the joke is. The word \"crusty\" has a double meaning here:\\n  - A pizza crust is the outer layer of a pizza, which is often crispy or crunchy.\\n  - The phrase \"feeling crusty\" is also an idiom that means feeling grumpy or irritable.\\n- The phrase \"had a lot of topping issues\" is also a play on words:\\n  - A pizza topping is a ingredient added on top of the pizza, such as cheese, pepperoni, or vegetables.\\n  - The phrase \"topping issues\" sounds like \"tough issues\" or \"problems\", implying that the pizza has emotional or psychological issues that it needs to work through in therapy.\\n\\nOverall, the joke is a play on words and uses the common format of a joke to create a humorous connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 253, 'total_tokens': 500, 'completion_time': 0.367460049, 'prompt_time': 0.065347236, 'queue_time': 0.045347873, 'total_time': 0.432807285}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e272e9b9-cf4a-4865-bcf6-331b93463de1-0', usage_metadata={'input_tokens': 253, 'output_tokens': 247, 'total_tokens': 500})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6d15-626a-8002-900a7304d02b'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-09T10:21:14.183741+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6780-6a77-8001-bc3793e6f439'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can get state of our workflow\n",
    "workflow.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f09182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why did the pizza go to therapy? \\n\\nBecause it was feeling crusty and had a lot of topping issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 43, 'total_tokens': 67, 'completion_time': 0.026194333, 'prompt_time': 0.084625438, 'queue_time': 0.061955262, 'total_time': 0.110819771}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8b8323f-712c-4afb-a662-fec948fb6e40-0', usage_metadata={'input_tokens': 43, 'output_tokens': 24, 'total_tokens': 67}), 'explanation': AIMessage(content='This is a joke about a pizza going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the pizza go to therapy?\" This is a common joke format where the punchline is a play on words or a unexpected twist.\\n- The punchline is \"Because it was feeling crusty and had a lot of topping issues.\" This is where the joke is. The word \"crusty\" has a double meaning here:\\n  - A pizza crust is the outer layer of a pizza, which is often crispy or crunchy.\\n  - The phrase \"feeling crusty\" is also an idiom that means feeling grumpy or irritable.\\n- The phrase \"had a lot of topping issues\" is also a play on words:\\n  - A pizza topping is a ingredient added on top of the pizza, such as cheese, pepperoni, or vegetables.\\n  - The phrase \"topping issues\" sounds like \"tough issues\" or \"problems\", implying that the pizza has emotional or psychological issues that it needs to work through in therapy.\\n\\nOverall, the joke is a play on words and uses the common format of a joke to create a humorous connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 253, 'total_tokens': 500, 'completion_time': 0.367460049, 'prompt_time': 0.065347236, 'queue_time': 0.045347873, 'total_time': 0.432807285}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e272e9b9-cf4a-4865-bcf6-331b93463de1-0', usage_metadata={'input_tokens': 253, 'output_tokens': 247, 'total_tokens': 500})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6d15-626a-8002-900a7304d02b'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-09T10:21:14.183741+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6780-6a77-8001-bc3793e6f439'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why did the pizza go to therapy? \\n\\nBecause it was feeling crusty and had a lot of topping issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 43, 'total_tokens': 67, 'completion_time': 0.026194333, 'prompt_time': 0.084625438, 'queue_time': 0.061955262, 'total_time': 0.110819771}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8b8323f-712c-4afb-a662-fec948fb6e40-0', usage_metadata={'input_tokens': 43, 'output_tokens': 24, 'total_tokens': 67})}, next=('gen_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6780-6a77-8001-bc3793e6f439'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-09T10:21:13.598629+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6022-6b92-8000-64a2953f6ce3'}}, tasks=(PregelTask(id='ef47082a-03c7-73c0-2cdd-00d1a4e8cf4e', name='gen_explanation', path=('__pregel_pull', 'gen_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='This is a joke about a pizza going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the pizza go to therapy?\" This is a common joke format where the punchline is a play on words or a unexpected twist.\\n- The punchline is \"Because it was feeling crusty and had a lot of topping issues.\" This is where the joke is. The word \"crusty\" has a double meaning here:\\n  - A pizza crust is the outer layer of a pizza, which is often crispy or crunchy.\\n  - The phrase \"feeling crusty\" is also an idiom that means feeling grumpy or irritable.\\n- The phrase \"had a lot of topping issues\" is also a play on words:\\n  - A pizza topping is a ingredient added on top of the pizza, such as cheese, pepperoni, or vegetables.\\n  - The phrase \"topping issues\" sounds like \"tough issues\" or \"problems\", implying that the pizza has emotional or psychological issues that it needs to work through in therapy.\\n\\nOverall, the joke is a play on words and uses the common format of a joke to create a humorous connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 253, 'total_tokens': 500, 'completion_time': 0.367460049, 'prompt_time': 0.065347236, 'queue_time': 0.045347873, 'total_time': 0.432807285}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e272e9b9-cf4a-4865-bcf6-331b93463de1-0', usage_metadata={'input_tokens': 253, 'output_tokens': 247, 'total_tokens': 500})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('gen_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6022-6b92-8000-64a2953f6ce3'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-09T10:21:12.826152+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6020-650f-bfff-c909225d18b4'}}, tasks=(PregelTask(id='73a3fba0-161d-c189-77da-89e854e13dec', name='gen_joke', path=('__pregel_pull', 'gen_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the pizza go to therapy? \\n\\nBecause it was feeling crusty and had a lot of topping issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 43, 'total_tokens': 67, 'completion_time': 0.026194333, 'prompt_time': 0.084625438, 'queue_time': 0.061955262, 'total_time': 0.110819771}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8b8323f-712c-4afb-a662-fec948fb6e40-0', usage_metadata={'input_tokens': 43, 'output_tokens': 24, 'total_tokens': 67})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6020-650f-bfff-c909225d18b4'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-09T10:21:12.825166+00:00', parent_config=None, tasks=(PregelTask(id='addb3119-d04c-a7a7-32a0-377f1da9c4c5', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can even see intermediate states as well\n",
    "list(workflow.get_state_history(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce6a7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pasta',\n",
       " 'joke': AIMessage(content='Why did the spaghetti go to therapy? \\n\\nBecause it was feeling a little \"twisted\" and had a lot of \"noodle\" issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 43, 'total_tokens': 74, 'completion_time': 0.019696397, 'prompt_time': 0.045835044, 'queue_time': 0.045904596, 'total_time': 0.065531441}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6b3a6325-0cd5-4c4b-925c-b097e9bbbd27-0', usage_metadata={'input_tokens': 43, 'output_tokens': 31, 'total_tokens': 74}),\n",
       " 'explanation': AIMessage(content='This is a joke about a spaghetti going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the spaghetti go to therapy?\" This is a common joke format where the punchline is a play on words or a clever twist on the situation.\\n\\n- The punchline is \"Because it was feeling a little \\'twisted\\' and had a lot of \\'noodle\\' issues.\" This is where the joke relies on wordplay.\\n\\n- \"Twisted\" has a double meaning here. Spaghetti is a type of pasta that is twisted or curved in shape. However, \"twisted\" can also mean emotionally disturbed or mentally unstable, which is why someone might go to therapy.\\n\\n- \"Noodle issues\" is another play on words. \"Noodle\" is a type of pasta, but it\\'s also a colloquialism for problems or issues. So, the joke is saying that the spaghetti has problems (noodle issues) and is emotionally disturbed (twisted).\\n\\nThe joke relies on a combination of wordplay and clever use of language to create a humorous effect.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 265, 'total_tokens': 488, 'completion_time': 0.293501066, 'prompt_time': 0.17992706, 'queue_time': 0.050712349, 'total_time': 0.473428126}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--44ea8459-00ca-4c47-82d5-0cc4c327d5f8-0', usage_metadata={'input_tokens': 265, 'output_tokens': 223, 'total_tokens': 488})}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAking config2 \n",
    "config2 = {'configurable': {'thread_id': '2'}}\n",
    "workflow.invoke({'topic':'pasta'}, config = config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "720c4cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pasta', 'joke': AIMessage(content='Why did the spaghetti go to therapy? \\n\\nBecause it was feeling a little \"twisted\" and had a lot of \"noodle\" issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 43, 'total_tokens': 74, 'completion_time': 0.019696397, 'prompt_time': 0.045835044, 'queue_time': 0.045904596, 'total_time': 0.065531441}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6b3a6325-0cd5-4c4b-925c-b097e9bbbd27-0', usage_metadata={'input_tokens': 43, 'output_tokens': 31, 'total_tokens': 74}), 'explanation': AIMessage(content='This is a joke about a spaghetti going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the spaghetti go to therapy?\" This is a common joke format where the punchline is a play on words or a clever twist on the situation.\\n\\n- The punchline is \"Because it was feeling a little \\'twisted\\' and had a lot of \\'noodle\\' issues.\" This is where the joke relies on wordplay.\\n\\n- \"Twisted\" has a double meaning here. Spaghetti is a type of pasta that is twisted or curved in shape. However, \"twisted\" can also mean emotionally disturbed or mentally unstable, which is why someone might go to therapy.\\n\\n- \"Noodle issues\" is another play on words. \"Noodle\" is a type of pasta, but it\\'s also a colloquialism for problems or issues. So, the joke is saying that the spaghetti has problems (noodle issues) and is emotionally disturbed (twisted).\\n\\nThe joke relies on a combination of wordplay and clever use of language to create a humorous effect.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 265, 'total_tokens': 488, 'completion_time': 0.293501066, 'prompt_time': 0.17992706, 'queue_time': 0.050712349, 'total_time': 0.473428126}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--44ea8459-00ca-4c47-82d5-0cc4c327d5f8-0', usage_metadata={'input_tokens': 265, 'output_tokens': 223, 'total_tokens': 488})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-755d-6a54-8002-fee7c2b66c9e'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-09T10:21:15.052296+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6fa7-66fb-8001-509f055a738f'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For thread id 2, state will also save but differently not in pizza one\n",
    "workflow.get_state(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6da3553c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why did the pizza go to therapy? \\n\\nBecause it was feeling crusty and had a lot of topping issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 43, 'total_tokens': 67, 'completion_time': 0.026194333, 'prompt_time': 0.084625438, 'queue_time': 0.061955262, 'total_time': 0.110819771}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8b8323f-712c-4afb-a662-fec948fb6e40-0', usage_metadata={'input_tokens': 43, 'output_tokens': 24, 'total_tokens': 67}), 'explanation': AIMessage(content='This is a joke about a pizza going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the pizza go to therapy?\" This is a common joke format where the punchline is a play on words or a unexpected twist.\\n- The punchline is \"Because it was feeling crusty and had a lot of topping issues.\" This is where the joke is. The word \"crusty\" has a double meaning here:\\n  - A pizza crust is the outer layer of a pizza, which is often crispy or crunchy.\\n  - The phrase \"feeling crusty\" is also an idiom that means feeling grumpy or irritable.\\n- The phrase \"had a lot of topping issues\" is also a play on words:\\n  - A pizza topping is a ingredient added on top of the pizza, such as cheese, pepperoni, or vegetables.\\n  - The phrase \"topping issues\" sounds like \"tough issues\" or \"problems\", implying that the pizza has emotional or psychological issues that it needs to work through in therapy.\\n\\nOverall, the joke is a play on words and uses the common format of a joke to create a humorous connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 253, 'total_tokens': 500, 'completion_time': 0.367460049, 'prompt_time': 0.065347236, 'queue_time': 0.045347873, 'total_time': 0.432807285}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e272e9b9-cf4a-4865-bcf6-331b93463de1-0', usage_metadata={'input_tokens': 253, 'output_tokens': 247, 'total_tokens': 500})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6d15-626a-8002-900a7304d02b'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-09T10:21:14.183741+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6780-6a77-8001-bc3793e6f439'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thread_id basically seems as different classes\n",
    "workflow.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6d2752f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pasta', 'joke': AIMessage(content='Why did the spaghetti go to therapy? \\n\\nBecause it was feeling a little \"twisted\" and had a lot of \"noodle\" issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 43, 'total_tokens': 74, 'completion_time': 0.019696397, 'prompt_time': 0.045835044, 'queue_time': 0.045904596, 'total_time': 0.065531441}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6b3a6325-0cd5-4c4b-925c-b097e9bbbd27-0', usage_metadata={'input_tokens': 43, 'output_tokens': 31, 'total_tokens': 74}), 'explanation': AIMessage(content='This is a joke about a spaghetti going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the spaghetti go to therapy?\" This is a common joke format where the punchline is a play on words or a clever twist on the situation.\\n\\n- The punchline is \"Because it was feeling a little \\'twisted\\' and had a lot of \\'noodle\\' issues.\" This is where the joke relies on wordplay.\\n\\n- \"Twisted\" has a double meaning here. Spaghetti is a type of pasta that is twisted or curved in shape. However, \"twisted\" can also mean emotionally disturbed or mentally unstable, which is why someone might go to therapy.\\n\\n- \"Noodle issues\" is another play on words. \"Noodle\" is a type of pasta, but it\\'s also a colloquialism for problems or issues. So, the joke is saying that the spaghetti has problems (noodle issues) and is emotionally disturbed (twisted).\\n\\nThe joke relies on a combination of wordplay and clever use of language to create a humorous effect.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 265, 'total_tokens': 488, 'completion_time': 0.293501066, 'prompt_time': 0.17992706, 'queue_time': 0.050712349, 'total_time': 0.473428126}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--44ea8459-00ca-4c47-82d5-0cc4c327d5f8-0', usage_metadata={'input_tokens': 265, 'output_tokens': 223, 'total_tokens': 488})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-755d-6a54-8002-fee7c2b66c9e'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-09T10:21:15.052296+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6fa7-66fb-8001-509f055a738f'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pasta', 'joke': AIMessage(content='Why did the spaghetti go to therapy? \\n\\nBecause it was feeling a little \"twisted\" and had a lot of \"noodle\" issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 43, 'total_tokens': 74, 'completion_time': 0.019696397, 'prompt_time': 0.045835044, 'queue_time': 0.045904596, 'total_time': 0.065531441}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6b3a6325-0cd5-4c4b-925c-b097e9bbbd27-0', usage_metadata={'input_tokens': 43, 'output_tokens': 31, 'total_tokens': 74})}, next=('gen_explanation',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6fa7-66fb-8001-509f055a738f'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-09T10:21:14.453375+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6db8-681d-8000-fa7e2bc3ab33'}}, tasks=(PregelTask(id='de98dcc1-ddeb-5aa7-b4ce-5e53f0ada277', name='gen_explanation', path=('__pregel_pull', 'gen_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='This is a joke about a spaghetti going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the spaghetti go to therapy?\" This is a common joke format where the punchline is a play on words or a clever twist on the situation.\\n\\n- The punchline is \"Because it was feeling a little \\'twisted\\' and had a lot of \\'noodle\\' issues.\" This is where the joke relies on wordplay.\\n\\n- \"Twisted\" has a double meaning here. Spaghetti is a type of pasta that is twisted or curved in shape. However, \"twisted\" can also mean emotionally disturbed or mentally unstable, which is why someone might go to therapy.\\n\\n- \"Noodle issues\" is another play on words. \"Noodle\" is a type of pasta, but it\\'s also a colloquialism for problems or issues. So, the joke is saying that the spaghetti has problems (noodle issues) and is emotionally disturbed (twisted).\\n\\nThe joke relies on a combination of wordplay and clever use of language to create a humorous effect.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 265, 'total_tokens': 488, 'completion_time': 0.293501066, 'prompt_time': 0.17992706, 'queue_time': 0.050712349, 'total_time': 0.473428126}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--44ea8459-00ca-4c47-82d5-0cc4c327d5f8-0', usage_metadata={'input_tokens': 265, 'output_tokens': 223, 'total_tokens': 488})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pasta'}, next=('gen_joke',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6db8-681d-8000-fa7e2bc3ab33'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-09T10:21:14.250652+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6db6-6125-bfff-f0e33cb7c28a'}}, tasks=(PregelTask(id='5bde2a61-3f70-343e-fd3c-5e662cd92882', name='gen_joke', path=('__pregel_pull', 'gen_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the spaghetti go to therapy? \\n\\nBecause it was feeling a little \"twisted\" and had a lot of \"noodle\" issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 43, 'total_tokens': 74, 'completion_time': 0.019696397, 'prompt_time': 0.045835044, 'queue_time': 0.045904596, 'total_time': 0.065531441}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6b3a6325-0cd5-4c4b-925c-b097e9bbbd27-0', usage_metadata={'input_tokens': 43, 'output_tokens': 31, 'total_tokens': 74})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6db6-6125-bfff-f0e33cb7c28a'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-09T10:21:14.249654+00:00', parent_config=None, tasks=(PregelTask(id='4b251668-8903-ffbf-ce6c-c4a4219c1118', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pasta'}),), interrupts=())]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intermediate values of config2\n",
    "list(workflow.get_state_history(config2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5932d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why did the pizza go to therapy? \\n\\nBecause it was feeling crusty and had a lot of topping issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 43, 'total_tokens': 67, 'completion_time': 0.026194333, 'prompt_time': 0.084625438, 'queue_time': 0.061955262, 'total_time': 0.110819771}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8b8323f-712c-4afb-a662-fec948fb6e40-0', usage_metadata={'input_tokens': 43, 'output_tokens': 24, 'total_tokens': 67}), 'explanation': AIMessage(content='This is a joke about a pizza going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the pizza go to therapy?\" This is a common joke format where the punchline is a play on words or a unexpected twist.\\n- The punchline is \"Because it was feeling crusty and had a lot of topping issues.\" This is where the joke is. The word \"crusty\" has a double meaning here:\\n  - A pizza crust is the outer layer of a pizza, which is often crispy or crunchy.\\n  - The phrase \"feeling crusty\" is also an idiom that means feeling grumpy or irritable.\\n- The phrase \"had a lot of topping issues\" is also a play on words:\\n  - A pizza topping is a ingredient added on top of the pizza, such as cheese, pepperoni, or vegetables.\\n  - The phrase \"topping issues\" sounds like \"tough issues\" or \"problems\", implying that the pizza has emotional or psychological issues that it needs to work through in therapy.\\n\\nOverall, the joke is a play on words and uses the common format of a joke to create a humorous connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 253, 'total_tokens': 500, 'completion_time': 0.367460049, 'prompt_time': 0.065347236, 'queue_time': 0.045347873, 'total_time': 0.432807285}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e272e9b9-cf4a-4865-bcf6-331b93463de1-0', usage_metadata={'input_tokens': 253, 'output_tokens': 247, 'total_tokens': 500})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6d15-626a-8002-900a7304d02b'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-09T10:21:14.183741+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6780-6a77-8001-bc3793e6f439'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why did the pizza go to therapy? \\n\\nBecause it was feeling crusty and had a lot of topping issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 43, 'total_tokens': 67, 'completion_time': 0.026194333, 'prompt_time': 0.084625438, 'queue_time': 0.061955262, 'total_time': 0.110819771}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8b8323f-712c-4afb-a662-fec948fb6e40-0', usage_metadata={'input_tokens': 43, 'output_tokens': 24, 'total_tokens': 67})}, next=('gen_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6780-6a77-8001-bc3793e6f439'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-09T10:21:13.598629+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6022-6b92-8000-64a2953f6ce3'}}, tasks=(PregelTask(id='ef47082a-03c7-73c0-2cdd-00d1a4e8cf4e', name='gen_explanation', path=('__pregel_pull', 'gen_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='This is a joke about a pizza going to therapy. Here\\'s a breakdown of the joke:\\n\\n- The setup is \"Why did the pizza go to therapy?\" This is a common joke format where the punchline is a play on words or a unexpected twist.\\n- The punchline is \"Because it was feeling crusty and had a lot of topping issues.\" This is where the joke is. The word \"crusty\" has a double meaning here:\\n  - A pizza crust is the outer layer of a pizza, which is often crispy or crunchy.\\n  - The phrase \"feeling crusty\" is also an idiom that means feeling grumpy or irritable.\\n- The phrase \"had a lot of topping issues\" is also a play on words:\\n  - A pizza topping is a ingredient added on top of the pizza, such as cheese, pepperoni, or vegetables.\\n  - The phrase \"topping issues\" sounds like \"tough issues\" or \"problems\", implying that the pizza has emotional or psychological issues that it needs to work through in therapy.\\n\\nOverall, the joke is a play on words and uses the common format of a joke to create a humorous connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 253, 'total_tokens': 500, 'completion_time': 0.367460049, 'prompt_time': 0.065347236, 'queue_time': 0.045347873, 'total_time': 0.432807285}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e272e9b9-cf4a-4865-bcf6-331b93463de1-0', usage_metadata={'input_tokens': 253, 'output_tokens': 247, 'total_tokens': 500})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('gen_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6022-6b92-8000-64a2953f6ce3'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-09T10:21:12.826152+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6020-650f-bfff-c909225d18b4'}}, tasks=(PregelTask(id='73a3fba0-161d-c189-77da-89e854e13dec', name='gen_joke', path=('__pregel_pull', 'gen_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the pizza go to therapy? \\n\\nBecause it was feeling crusty and had a lot of topping issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 43, 'total_tokens': 67, 'completion_time': 0.026194333, 'prompt_time': 0.084625438, 'queue_time': 0.061955262, 'total_time': 0.110819771}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8b8323f-712c-4afb-a662-fec948fb6e40-0', usage_metadata={'input_tokens': 43, 'output_tokens': 24, 'total_tokens': 67})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08d66b-6020-650f-bfff-c909225d18b4'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-09T10:21:12.825166+00:00', parent_config=None, tasks=(PregelTask(id='addb3119-d04c-a7a7-32a0-377f1da9c4c5', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Intermediate values of config2\n",
    "list(workflow.get_state_history(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff983d37",
   "metadata": {},
   "source": [
    "## Time Travel\n",
    "Here we can reach to any intermediate state by using their checkpoint id. Suppose we want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f0601c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f08c03a-5bda-6c48-8000-ad51063f0f3e'}}, metadata=None, created_at=None, parent_config=None, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state({'configurable':{'thread_id': '1', 'checkpoint_id': '1f08c03a-5bda-6c48-8000-ad51063f0f3e'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45fe772c",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyInputError",
     "evalue": "Received no input for __start__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyInputError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Invoking the workflow from the state where we just had the topic\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcheckpoint_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1f08c03a-5bda-6c48-8000-ad51063f0f3e\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langgraph-Tutorials\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langgraph-Tutorials\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2582\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2579\u001b[39m runtime = parent_runtime.merge(runtime)\n\u001b[32m   2580\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001b[32m-> \u001b[39m\u001b[32m2582\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2583\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# create runner\u001b[39;49;00m\n\u001b[32m   2604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPregelRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2606\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_RUNNER_SUBMIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWeakMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2609\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_KEY_NODE_FINISHED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2610\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2611\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# enable subgraph streaming\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langgraph-Tutorials\\myenv\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:1044\u001b[39m, in \u001b[36mSyncPregelLoop.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28mself\u001b[39m.stop = \u001b[38;5;28mself\u001b[39m.step + \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m   1043\u001b[39m \u001b[38;5;28mself\u001b[39m.checkpoint_previous_versions = \u001b[38;5;28mself\u001b[39m.checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdated_channels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdated_channels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langgraph-Tutorials\\myenv\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:670\u001b[39m, in \u001b[36mPregelLoop._first\u001b[39m\u001b[34m(self, input_keys, updated_channels)\u001b[39m\n\u001b[32m    668\u001b[39m     \u001b[38;5;28mself\u001b[39m._put_checkpoint({\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m CONFIG_KEY_RESUMING \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m configurable:\n\u001b[32m--> \u001b[39m\u001b[32m670\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyInputError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived no input for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    671\u001b[39m \u001b[38;5;66;03m# update config\u001b[39;00m\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_nested:\n",
      "\u001b[31mEmptyInputError\u001b[39m: Received no input for __start__"
     ]
    }
   ],
   "source": [
    "# Invoking the workflow from the state where we just had the topic\n",
    "workflow.invoke(None, {'configurable':{'thread_id': '1', 'checkpoint_id': '1f08c03a-5bda-6c48-8000-ad51063f0f3e' }} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc84cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(workflow.get_state_history(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ae6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_state({'configurable':{'thread_id': '1', 'checkpoint_id': '1f08c03a-5bda-6c48-8000-ad51063f0f3e'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91ed9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
